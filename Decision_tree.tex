\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Decision Tree}
\author{sumit singh}
\date{\today}

\begin{document}

\maketitle

\section{Questions}
\begin{itemize}
    \item Is Decision Tree parametric or non parametric?
    \item What is the loss function of DT?
    \item Is DT an algo or a model with a bunch of algos?
    \item What are the algos in DT?
    \item Explain CHAID, CART. What else are there?
    \item Continuous and categorical input and output variables!
\end{itemize}
\section{Introduction}
Partition the input space into recursively generated rectangles. Recursively splitting of region. \\
Biggest advantage of DT is interpretability. (At the other extreme is neural networks which is incomprehensible) . This helps in very compactly describing  the segmentation as a tree. An easily understandable tree. \\
Neural networks are universal approximators. So are DTs. The parameters can grow unbounded. \\
In DT, you can repeat the variables. \\
DTs are \textbf{non parametric}. It can keep growing. You can keep adding the parameters as you go along. \\
\section{Regression Trees}
So far, we did partitioning. Now regression trees.\\
\section{References}
\end{document}